# EU AI Act – Cheatsheet  

**12 Quick Facts**  
1. Definition „KI-System“  
2. Risikostufen  
3. Verbotene Praktiken  
4. High-Risk-Pflichten  
5. Konformitätsbewertung  
6. Marktüberwachung  
7. Transparenzauflagen  
8. Datengovernance  
9. Human Oversight  
10. Genauigkeit & Robustheit  
11. Aufzeichnungspflichten  
12. Durchsetzung & Bußgelder  

### Zweck des EU AI Acts (Art 1(1)
- Besseres Funktionieren des Binnenmarkts
- Förderung einer **auf den Menschen ausgerichteten** KI
- Schutz der:
  - Gesundheit
  - Sicherheit
  - Grundrechte (Basis: Charta der Vereinten Nationen)
    - Demokratie
    - Rechtsstaatlichkeit
    - Umweltschutz
- Schutz vor schädlichen Auswirkungen von KI-Systemen allgemein
- Unterstützung der Innovation

### KI-Campus · AI Act Essentials – Modul 1.1.1 „Eine Technologie wie keine Andere“[^kc1]

| Merkmal | KI-System | Traditionelle Software |
|---------|-----------|------------------------|
| **Lernfähigkeit** | Lernt aus Daten, passt Modelle an | Keine eigene Lernfähigkeit – folgt festem Code |
| **Verhalten über Zeit** | Kann sich dynamisch ändern | Vorhersehbar; ändert sich nur bei Updates |
| **Weiterentwicklung** | Neues (Re-)Training möglich, teils sogar im Feld | Erfordert manuellen Code-Eingriff & Release |
| **Unbekannte Szenarien** | Muss improvisieren – Risiko falscher Reaktion bei Datenlücken | Befolgt fixe Regeln, kann nicht improvisieren |

> **Kurz-Erläuterung:** KI-Systeme sind *datengetrieben* und entwickeln sich nach der Inbetriebnahme weiter. Das erklärt die strengen Vorgaben zu **Risikomanagement (Art. 9)** und **Post-Market-Monitoring (Art. 61 ff.)** im EU AI Act.

[^kc1]: Quelle: KI-Campus Online-Kurs *AI Act Essentials*, Modul 1 – 2025 · Lizenz CC BY-SA 4.0
